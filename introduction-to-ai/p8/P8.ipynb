{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Task P8**\n",
    "## Analyzing Twitter Data using NLP\n",
    "\n",
    "##### This task focuses on analyzing user replies to Covid-19 news published on the social media platform X (formerly known as Twitter) using some basic natural language processing (NLP) techniques. \n",
    "\n",
    "##### The task uses the `replies.csv` dataset, which contains the information about user replies to the Covid-19 news posted on Twitter. The columns capture the content related to the individual replies such as `text` (the actual text content of the reply), `id` (a unique ID for the reply itself), `conversation_id` (linking the reply to a specific conversation thread), `in_reply_to_user_id` (identifying the target user of the reply), and `possibly_sensitive` (indicating if the content may be sensitive). Additional informaiton include `author_id` (the unique ID of the reply's author), `author_followers` (the count of the author's followers),`author_tweets` (total tweets made by the author), and `author_location` (the geographical location of the author). Moreover, engagement metrics are tracked through columns like `retweets`, `replies`, `likes`, and `quote_count`. Time and location metadata are captured by `created_at` and `geo`, respectively, with `account` specifying the account name of the news publishers (e.g., BBC).\n",
    "\n",
    "<img src=\"pic.png\" alt=\"SIT112 News Tweets!\" width=\"1800\" height=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### A. Instructions\n",
    "\n",
    "1. `To complete this task, you must first study the solution notebook; then try to do it yourself. You can copy the solutions into ChatGPT and ask for clarification or more examples.`\n",
    "2. Complete and submit the TaskCompletionReport form in PDF format using Ontrack. You can do this by the end of Week 12, but feedback will only be provided for submissions received by 11 AM of the due date.\n",
    "3. Do **not** include the solution (yours or the one provided to you) in your submission.\n",
    "4. The workshops are the primary venue for you to seek help if you need any clarification/assitance. The tutors are there to help you complete and submit the tasks. Please avoid emailing your code or screenshots to the tutors outside workshop hours. \n",
    "5. Consider using online resources such as ChatGPT to strenghten your undertanding of the task. \n",
    "\n",
    "Good luck :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required modules are installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "# The following lines should install all libraries you need - you can install the libraries manually if the script did not work \n",
    "required_modules = ['pandas', 'seaborn', 'matplotlib', 'numpy', 'datetime', 'sklearn', 'nltk', 'textblob', 'textblob', 'collections', 'numpy', 'warnings']\n",
    "for module in required_modules:\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "    except ImportError:\n",
    "        print(f\"{module} module not found. Installing...\")\n",
    "        subprocess.check_call(['pip', 'install', module])\n",
    "\n",
    "print(\"All required modules are installed.\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from textblob import TextBlob\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set the maximum number of columns and rows displayed\n",
    "pd.set_option('display.max_columns', None)  # None means no limit\n",
    "pd.set_option('display.max_rows', None)  # None means no limit\n",
    "# You can also adjust the width of each column and the maximum column width\n",
    "pd.set_option('display.max_colwidth', None)  # None means no truncation on column width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Write Python code that performs (answers) the following operations (questions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Read the data from the .csv file into a DataFrame and display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 2. Clean the reply texts as listed below. You can use ChatGPT to generate regular expressions for these cleaning operations. \n",
    "\n",
    "- Remove @ Mentions: Strip out any @ mentions in the reply texts, which typically refer to other users and are not relevant for general analysis.\n",
    "- Remove Hashtags: Eliminate the '#' symbol but keep the subsequent text, which might be relevant for understanding the topic of the reply.\n",
    "- Remove Retweet Indicators: Remove any 'RT' symbols used to indicate retweets, as they do not contribute to text content.\n",
    "- Remove URLs: Strip out any web links (URLs), which are common in reply texts but irrelevant to text analysis.\n",
    "- Remove Punctuation: Eliminate all punctuation marks to reduce variability in the reply texts.\n",
    "- Convert to Lowercase: Standardize all reply texts to lowercase to ensure uniformity in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Remove from the reply texts the stopwords and the custom list of words that are unwanted:\n",
    "\n",
    "- Utilize a list of predefined stopwords from NLTK tailored for the English language (from nltk.corpus import stopwords).\n",
    "- Define a custom list of words to be excluded that are specifically irrelevant or overused in the reply texts.\n",
    "- Remove stopwords and custom words: filter out these words from the (reply) text to focus on more meaningful words for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. What are the 5 most frequent words in the replies per account (news publisher, e.g., BBC)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### 5. Classify the sentiment of each reply as positive, negative, or neutral based on the `text` column. Then visualize the ratio of the replies with positive, negative, or neutral sentiments per news publisher (account). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Learn more\n",
    "* https://www.sciencedirect.com/science/article/pii/S2468696423000125\n",
    "* https://youtu.be/toM78JGJ_4s?si=8ESJ-yOV_H1iX74r\n",
    "* https://youtu.be/QpzMWQvxXWk?si=CPvNgnZo3jsW4HL5\n",
    "* https://youtu.be/o7OqhzMcDfs?si=9iFeYZq4TlVCMMRb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
